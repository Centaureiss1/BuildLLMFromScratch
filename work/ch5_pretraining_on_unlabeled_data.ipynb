{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  This chapter covers\n",
    "Computing the training and validation set losses \n",
    "to assess the quality of LLM-generated text \n",
    "during training\n",
    "\n",
    "Implementing a training function and pretraining \n",
    "the LLM\n",
    "\n",
    "Saving and loading model weights to continue \n",
    "training an LLM\n",
    "\n",
    "Loading pretrained weights from OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from build_llm_utils import GPTModel\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 256,   # We shorten the context length from 1,024 to 256 tokens.\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12, \n",
    "    \"drop_rate\": 0.1,      \n",
    "    \"qkv_bias\": False\n",
    "}\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you rentingetic wasnم refres RexMeCHicular stren\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "from build_llm_utils import generate_text_simple\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # .unsqueeze(0) adds the batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0)     # Removes batch dimension\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the text generation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  two input examples for the GPT model (\"every effort moves\" and \"I really like\")\n",
    "inputs = torch.tensor([[16833, 3626, 6100],     # [\"every effort moves\",\n",
    "                        [40,    1107, 588]])    #  \"I really like\"]\n",
    "\n",
    "targets = torch.tensor([[3626, 6100, 345  ],  # [\" effort moves you\",\n",
    "                        [1107, 588, 11311]])  #  \" really like chocolate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "# feed the inputs into the model to calculate logits vectors\n",
    "with torch.no_grad():    \n",
    "    logits = model(inputs)\n",
    "probas = torch.softmax(logits, dim=-1)    \n",
    "print(probas.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[[16657],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"Token IDs:\\n\", token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1: Armed heNetflix\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1:\"\n",
    "      f\"{token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")\n",
    "\n",
    "#  it has not been trained yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([7.4541e-05, 3.1061e-05, 1.1563e-05])\n",
      "Text 2: tensor([1.0337e-05, 5.6776e-05, 4.7559e-06])\n"
     ]
    }
   ],
   "source": [
    "# print the initial softmax probability scores\n",
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]] # [batch, tokens, embeddings]\n",
    "print(\"Text 1:\", target_probas_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 2:\", target_probas_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7764, -12.2561])\n",
      "tensor(-10.7940)\n",
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "# calculate the loss for the probability scores of the two example batches\n",
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(log_probas)\n",
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(avg_log_probas)\n",
    "neg_avg_log_probas = avg_log_probas * -1\n",
    "print(neg_avg_log_probas)\n",
    "\n",
    "# During training the model first outputs logits, which are then converted to probability distributions by softmax (or other methods), and then the probabilities corresponding to the correct targets are extracted. Taking the logarithm of these probabilities, and then taking the negative mean, we get the negative log likelihood loss (NLL loss), and the goal of training is to minimize this loss so that the model assigns a higher probability to the correct target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257])\n",
      "Targets shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(\"Logits shape:\", logits.shape)\n",
    "print(\"Targets shape:\", targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flattened targets: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "# For the cross_entropy loss function in PyTorch, we want to flatten these tensors\n",
    "logits_flat = logits.flatten(0, 1)\n",
    "targets_flat = targets.flatten()\n",
    "print(\"Flattened logits:\", logits_flat.shape)\n",
    "print(\"Flattened targets:\", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "# targets_flat is the index of target logits_flat's token we want to calculate loss\n",
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perplexity can be calculated as perplexity = torch.exp(loss), which returns\n",
    "tensor(48725.8203) when applied to the previously calculated loss. \n",
    "Perplexity is often considered more interpretable than the raw loss value because it sig\n",
    "nifies the effective vocabulary size about which the model is uncertain at each step. In\n",
    "the given example, this would translate to the model being unsure about which among\n",
    "48,725 tokens in the vocabulary to generate as the next token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(48725.8203)\n"
     ]
    }
   ],
   "source": [
    "# Perplexity\n",
    "print(torch.exp(loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the-verdict.txt to train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../the-verdict.txt\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    text_data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20479\n",
      "Tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a train_ratio\n",
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloader\n",
    "from build_llm_utils import create_dataloader_v1\n",
    "torch.manual_seed(123)\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "# iterate through the data loaders to ensure that theywere created correctly\n",
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "    \n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement a utility function to calculate the cross entropy loss for one batch\n",
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch = input_batch.to(device)        \n",
    "    target_batch = target_batch.to(device)      \n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(\n",
    "        logits.flatten(0, 1), target_batch.flatten()\n",
    "    )\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Function to compute the training and validation loss for Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computes the loss over all the batches sampled by a given data loader\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader) # Iteratives over all batches if no fixed num_batches is specified\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))  \n",
    "\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(\n",
    "                input_batch, target_batch, model, device\n",
    "            )\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 10.987583266364204\n",
      "Validation loss: 10.98110580444336\n"
     ]
    }
   ],
   "source": [
    "# see this calc_loss_loader function in action\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)  \n",
    "with torch.no_grad():                                       \n",
    "    train_loss = calc_loss_loader(train_loader, model, device)   \n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally! Train a LLM\n",
    "8 steps for training a LLM:\n",
    "1. Iterate over training epochs\n",
    "2. Iterate over batches in each training epoch\n",
    "3. Reset loss gradients from previous batch iteration\n",
    "4. Calculate loss on current batch\n",
    "5. Backward pass to calculate loss gradients\n",
    "6. Update model weights using loss gradients\n",
    "7. Print training and validation set losses\n",
    "8. Generate sample text for visual inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The main function for pretraining LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader,\n",
    "               optimizer, device, num_epochs,\n",
    "               eval_freq, eval_iter, start_context, tokenizer):\n",
    "    #  Initializes lists to track losses and tokens seen\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []   \n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    for epoch in range(num_epochs):   \n",
    "        model.train()\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()  \n",
    "            loss = calc_loss_batch(\n",
    "                input_batch, target_batch, model, device\n",
    "            )\n",
    "            loss.backward()                    \n",
    "            optimizer.step()                   \n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % eval_freq == 0:   \n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                    f\"Train loss {train_loss:.3f}, \"\n",
    "                    f\"Val loss {val_loss:.3f}\"\n",
    "                )\n",
    "        \n",
    "        generate_and_print_sample(                     \n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval() \n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(\n",
    "            train_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "        val_loss = calc_loss_loader(\n",
    "            val_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "# Using the trained model, generate a new piece of text based on the starting text start_context, and print it out\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))     \n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training a GPTModel instance for 10 epochs using an\n",
    "AdamW optimizer and the train_model_simple function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.817, Val loss 9.928\n",
      "Ep 1 (Step 000005): Train loss 8.067, Val loss 8.334\n",
      "Every effort moves you,,,,,,,,,,,,.                                     \n",
      "Ep 2 (Step 000010): Train loss 6.624, Val loss 7.051\n",
      "Ep 2 (Step 000015): Train loss 6.049, Val loss 6.603\n",
      "Every effort moves you, the,, and,,,,,,, and,.                                   \n",
      "Ep 3 (Step 000020): Train loss 5.549, Val loss 6.501\n",
      "Ep 3 (Step 000025): Train loss 5.413, Val loss 6.366\n",
      "Every effort moves you, and to the of the of the of the, and I had. Gis, and, and, and, and, and, and I had, and, and, and, and, and, and, and, and, and,\n",
      "Ep 4 (Step 000030): Train loss 4.912, Val loss 6.283\n",
      "Ep 4 (Step 000035): Train loss 4.665, Val loss 6.310\n",
      "Every effort moves you of the picture.                        \"I\"IHe the picture\"I\"I           \n",
      "Ep 5 (Step 000040): Train loss 3.966, Val loss 6.152\n",
      "Every effort moves you know the                          \"Oh, and his pictures a, and he said.          \n",
      "Ep 6 (Step 000045): Train loss 3.626, Val loss 6.197\n",
      "Ep 6 (Step 000050): Train loss 3.061, Val loss 6.123\n",
      "Every effort moves you know the fact, and pushed one of the to the fact by his last word.        \"Oh, and I was his pictures--I looked up at the fact, and up and down the room, I had\n",
      "Ep 7 (Step 000055): Train loss 2.943, Val loss 6.154\n",
      "Ep 7 (Step 000060): Train loss 2.211, Val loss 6.121\n",
      "Every effort moves you know,\" was one of the picture for a smile that I felt to see a so that he was a little to me to have to see a smile behind his pictures.  \"--and it, the donkey. \"There were days when I\n",
      "Ep 8 (Step 000065): Train loss 1.770, Val loss 6.139\n",
      "Ep 8 (Step 000070): Train loss 1.462, Val loss 6.223\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the fact with a little: \"Yes--and by me to me to have to see a smile behind his close grayish beard--as if he had the donkey. \"There were days when I\n",
      "Ep 9 (Step 000075): Train loss 1.132, Val loss 6.248\n",
      "Ep 9 (Step 000080): Train loss 0.855, Val loss 6.281\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  \"Oh, and I remember getting off a prodigious phrase about the honour being _mine_--because he didn't want\n",
      "Ep 10 (Step 000085): Train loss 0.625, Val loss 6.395\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=0.0004, weight_decay=0.1\n",
    ")\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create a simple plot that shows the training and validation set losses side by side\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(\n",
    "        epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\"\n",
    "    )\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax2 = ax1.twiny()                  \n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)    \n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)\n",
    "\n",
    "# it’s overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Decoding strategies to control randomness\n",
    "temperature scaling and top-k sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you?\"\n",
      "\n",
      "\"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# plug the GPTModel instance (model) into the generate_text_simple function,\n",
    "# which uses the LLM to generate one token at a time\n",
    "\n",
    "model.to(\"cpu\")\n",
    "model.eval()\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Temperature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
